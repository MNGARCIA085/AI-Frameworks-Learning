{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a50e9715",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: red;\">This is centered red text</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6cad22",
   "metadata": {},
   "source": [
    "TBALE OF CONTENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f465b73",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## <font color='blue'> 1. Introduction </font>\n",
    "\n",
    "This notebook explores how to build custom models in TensorFlow, focusing on implementing custom training loops. Additionally, we delve into Graph Convolutional Networks (GCNs) and their applications.\n",
    "\n",
    "To put theory into practice, we implement a GCN model for the Karate Club dataset, a classic benchmark for graph-based learning. This will help reinforce key concepts such as:\n",
    "\n",
    "- Building models beyond Keras' predefined layers\n",
    "- Writing custom training loops for greater flexibility\n",
    "- Understanding and implementing Graph Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc270ee0",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## <font color='blue'> 2. Setup </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "150e316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spektral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ab1b2bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "from spektral.data import Dataset, Graph\n",
    "from spektral.layers import GCNConv\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0219db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e800d7",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## <font color='blue'> 3.  Data </font>\n",
    "\n",
    "We will use The Karate Club dataset, which is a well-known social network dataset that represents friendships in a karate club. It consists of 34 nodes (members of the club) and 78 edges (friendships).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cd02d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Karate Club dataset (networkx)\n",
    "G = nx.karate_club_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119361f5",
   "metadata": {},
   "source": [
    "<a name=\"3.1\"></a>\n",
    "### <font color='#1f618d'> 3.1.  Exploration </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f77a2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a962a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3d056b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127ffbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4b85961",
   "metadata": {},
   "source": [
    "<a name=\"3.2\"></a>\n",
    "### <font color='#1f618d'> 3.2. Pre-processing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e63bb6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of nodes\n",
    "num_nodes = len(G)\n",
    "num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "846534d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute adjacency matrix and normalize it\n",
    "#adj = nx.adjacency_matrix(G).astype(np.float32)\n",
    "adj = (nx.adjacency_matrix(G) > 0).astype(np.float32)\n",
    "adj += sp.eye(adj.shape[0])  # Add self-loops\n",
    "degree_matrix = np.array(adj.sum(axis=1)).flatten()\n",
    "D_inv_sqrt = np.diag(1.0 / np.sqrt(degree_matrix))\n",
    "adj_normalized = D_inv_sqrt @ adj @ D_inv_sqrt\n",
    "adj = tf.convert_to_tensor(adj_normalized, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "49351588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([34, 34])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a731dd",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bab77c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute node features\n",
    "one_hot_features = np.eye(num_nodes, dtype=np.float32)\n",
    "degrees = np.array([G.degree(n) for n in G.nodes()], dtype=np.float32).reshape(-1, 1)\n",
    "clustering_coeffs = np.array([nx.clustering(G, n) for n in G.nodes()], dtype=np.float32).reshape(-1, 1)\n",
    "betweenness = np.array(list(nx.betweenness_centrality(G).values()), dtype=np.float32).reshape(-1, 1)\n",
    "pagerank = np.array(list(nx.pagerank(G).values()), dtype=np.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e1d79cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 6.],\n",
       "       [ 3.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 5.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 5.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 2.],\n",
       "       [ 4.],\n",
       "       [ 3.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 6.],\n",
       "       [12.],\n",
       "       [17.]], dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7e0e4d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numerical features\n",
    "scaler = StandardScaler() # Standardize features by removing the mean and scaling to unit variance.\n",
    "        # (z-u)/s\n",
    "    # where u is the mean of the training samples or zero if with_mean=False, \n",
    "    #and s is the standard deviation of the training samples or one if with_std=False.\n",
    "numeric_features = scaler.fit_transform(np.hstack([degrees, clustering_coeffs, betweenness, pagerank]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4482e8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Means: [4.58823529 0.57063848 0.04400624 0.02941176]\n",
      "Feature Standard Deviations: [3.82036068 0.34226601 0.09254295 0.02236985]\n"
     ]
    }
   ],
   "source": [
    "# Access mean and standard deviation\n",
    "print(\"Feature Means:\", scaler.mean_)  # Mean of each column before scaling\n",
    "print(\"Feature Standard Deviations:\", scaler.scale_)  # Standard deviation of each column before scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3a24ab1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.987091  ,  1.1548032 ,  1.4165585 ,  0.36953703, -0.41572914,\n",
       "       -0.15397376, -0.15397376, -0.15397376,  0.10778163, -0.6774846 ,\n",
       "       -0.41572914, -0.93924   , -0.6774846 ,  0.10778163, -0.6774846 ,\n",
       "       -0.6774846 , -0.6774846 , -0.6774846 , -0.6774846 , -0.41572914,\n",
       "       -0.6774846 , -0.6774846 , -0.6774846 ,  0.10778163, -0.41572914,\n",
       "       -0.41572914, -0.6774846 , -0.15397376, -0.41572914, -0.15397376,\n",
       "       -0.15397376,  0.36953703,  1.9400693 ,  3.2488465 ], dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the first column (standardized degrees)\n",
    "standardized_degrees = numeric_features[:, 0]\n",
    "standardized_degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ed874a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all features\n",
    "features = np.hstack([one_hot_features, numeric_features])\n",
    "features = tf.convert_to_tensor(features, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0f5bd796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([34, 38])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7984a1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([38])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "338050c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(38,), dtype=float32, numpy=\n",
       "array([ 1.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  2.987091 ,\n",
       "       -1.2289811,  4.253474 ,  2.6417842], dtype=float32)>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0] # one hot for nodes, and then other 4 features (degrees......)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d938f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels (0 for 'Mr. Hi' club, 1 for 'Officer' club)\n",
    "labels = np.array([G.nodes[i]['club'] != 'Mr. Hi' for i in range(num_nodes)], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a6e33256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34,)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fe740f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30746ac",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b3ffaa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "train_mask = np.zeros(num_nodes, dtype=bool)\n",
    "train_mask[:17] = True  # First 17 nodes for training; arbitrary value\n",
    "test_mask = ~train_mask\n",
    "train_mask = tf.convert_to_tensor(train_mask)\n",
    "test_mask = tf.convert_to_tensor(test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "25314b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(34,), dtype=bool, numpy=\n",
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False])>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mask # first 17s are true and the other false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "40e99444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(34,), dtype=bool, numpy=\n",
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True])>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mask # last 34-17=17 are true, and the other are false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853fa21e",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## <font color='blue'> 4. Model </font>\n",
    "\n",
    "We will build the following model:\n",
    "\n",
    "........................\n",
    "\n",
    "\n",
    "this model can be used to predict group memberships of each club member. The goal is to classify nodes into two groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dab8e3",
   "metadata": {},
   "source": [
    "First, let's implement the GCN Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2d357ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GCN layer\n",
    "class GCNLayer(Layer):\n",
    "    \"\"\"\n",
    "    A Graph Convolutional Network (GCN) layer.\n",
    "\n",
    "    This layer performs graph convolution by aggregating information from neighboring nodes \n",
    "    using the adjacency matrix. It applies a linear transformation followed by an optional \n",
    "    activation function.\n",
    "\n",
    "    Args:\n",
    "        units (int): Number of output features.\n",
    "        activation (str or callable, optional): Activation function to apply. Default is None.\n",
    "        l2_reg (float, optional): L2 regularization factor for weight decay. Default is 1e-3.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, units, activation=None, l2_reg=1e-3, **kwargs):\n",
    "        super(GCNLayer, self).__init__(**kwargs)\n",
    "        self.units = units  # Number of output features\n",
    "        self.activation = tf.keras.activations.get(activation)  # Activation function\n",
    "        self.l2_reg = l2_reg  # L2 regularization factor\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"Initialize the layer's weights.\"\"\"\n",
    "        num_features = input_shape[0][-1]  # Get the number of input features\n",
    "\n",
    "        # Weight matrix for feature transformation\n",
    "        self.w = self.add_weight(shape=(num_features, self.units),\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 regularizer=tf.keras.regularizers.l2(self.l2_reg),\n",
    "                                 trainable=True)\n",
    "\n",
    "        # Bias term\n",
    "        self.b = self.add_weight(shape=(self.units,), initializer='zeros', trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass of the GCN layer.\n",
    "\n",
    "        Args:\n",
    "            inputs (tuple): A tuple containing:\n",
    "                - features (tf.Tensor): Node feature matrix of shape (num_nodes, num_features).\n",
    "                - adj (tf.Tensor): Adjacency matrix of shape (num_nodes, num_nodes).\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The transformed node features after applying graph convolution.\n",
    "        \"\"\"\n",
    "        features, adj = inputs  # Unpack inputs: node features and adjacency matrix\n",
    "\n",
    "        # Apply linear transformation to node features\n",
    "        support = tf.matmul(features, self.w)\n",
    "\n",
    "        # Aggregate neighbor information using adjacency matrix\n",
    "        adj_features = tf.matmul(adj, support)\n",
    "\n",
    "        # Add bias term\n",
    "        output = adj_features + self.b\n",
    "\n",
    "        # Apply activation function (if specified)\n",
    "        return self.activation(output) if self.activation else output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbd1099",
   "metadata": {},
   "source": [
    "Now, let's implement the entire model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "98b606b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GCN Model\n",
    "class GCNModel(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    A Graph Convolutional Network (GCN) model using two GCN layers.\n",
    "\n",
    "    This model consists of:\n",
    "    - Two GCN layers for message passing\n",
    "    - Batch normalization for stable training\n",
    "    - Dropout for regularization\n",
    "\n",
    "    Args:\n",
    "        hidden_units (int): Number of hidden units in the first GCN layer.\n",
    "        num_classes (int): Number of output classes (logits).\n",
    "        dropout_rate (float, optional): Dropout rate for regularization. Default is 0.2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_units, num_classes, dropout_rate=0.2):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.gcn1 = GCNLayer(hidden_units, activation='relu')  # First GCN layer with ReLU activation\n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)  # Dropout after first layer\n",
    "        self.gcn2 = GCNLayer(num_classes)  # Second GCN layer (outputs raw logits)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)  # Dropout after second layer\n",
    "        self.batch_norm = tf.keras.layers.BatchNormalization()  # Batch normalization for stability\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"\n",
    "        Forward pass of the GCN model.\n",
    "\n",
    "        Args:\n",
    "            inputs (tuple): A tuple containing:\n",
    "                - features (tf.Tensor): Node feature matrix of shape (num_nodes, num_features).\n",
    "                - adj (tf.Tensor): Adjacency matrix of shape (num_nodes, num_nodes).\n",
    "            training (bool, optional): Whether the model is in training mode (for dropout and batch norm). Default is False.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The output logits of shape (num_nodes, num_classes).\n",
    "        \"\"\"\n",
    "        features, adj = inputs  # Unpack inputs: node features and adjacency matrix\n",
    "\n",
    "        # First GCN layer with batch normalization and dropout\n",
    "        x = self.gcn1((features, adj))\n",
    "        x = self.batch_norm(x, training=training)  # Batch norm active only in training mode\n",
    "        x = self.dropout1(x, training=training)  # Apply dropout if training\n",
    "\n",
    "        # Second GCN layer followed by dropout\n",
    "        x = self.gcn2((x, adj))\n",
    "        x = self.dropout2(x, training=training)  # Apply dropout if training\n",
    "\n",
    "        return x  # Return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d51d0083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = GCNModel(hidden_units=16, num_classes=2, dropout_rate=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4020ee63",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a>\n",
    "## <font color='blue'> 5. Training </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cb4112ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) # the model returns logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "25776862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d0c5b3",
   "metadata": {},
   "source": [
    "### Custom training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "850c3ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.9477463960647583, Test Accuracy: 0.47058823704719543\n",
      "Epoch 10, Loss: 0.305582195520401, Test Accuracy: 0.1764705926179886\n",
      "Epoch 20, Loss: 0.16731642186641693, Test Accuracy: 0.1764705926179886\n",
      "Epoch 30, Loss: 0.07087139040231705, Test Accuracy: 0.1764705926179886\n",
      "Epoch 40, Loss: 0.1343555897474289, Test Accuracy: 0.1764705926179886\n",
      "Epoch 50, Loss: 0.12809759378433228, Test Accuracy: 0.1764705926179886\n",
      "Epoch 60, Loss: 0.09694959968328476, Test Accuracy: 0.1764705926179886\n",
      "Epoch 70, Loss: 0.057687193155288696, Test Accuracy: 0.1764705926179886\n",
      "Epoch 80, Loss: 0.05998469144105911, Test Accuracy: 0.1764705926179886\n",
      "Epoch 90, Loss: 0.04889430105686188, Test Accuracy: 0.1764705926179886\n",
      "Epoch 100, Loss: 0.010954556986689568, Test Accuracy: 0.1764705926179886\n",
      "Epoch 110, Loss: 0.015112942084670067, Test Accuracy: 0.1764705926179886\n",
      "Epoch 120, Loss: 0.027831045910716057, Test Accuracy: 0.1764705926179886\n",
      "Epoch 130, Loss: 0.04748344421386719, Test Accuracy: 0.23529411852359772\n",
      "Epoch 140, Loss: 0.008183041587471962, Test Accuracy: 0.23529411852359772\n",
      "Epoch 150, Loss: 0.13553300499916077, Test Accuracy: 0.29411765933036804\n",
      "Epoch 160, Loss: 0.05585852265357971, Test Accuracy: 0.29411765933036804\n",
      "Epoch 170, Loss: 0.041894324123859406, Test Accuracy: 0.4117647111415863\n",
      "Epoch 180, Loss: 0.008990745060145855, Test Accuracy: 0.47058823704719543\n",
      "Epoch 190, Loss: 0.005965592805296183, Test Accuracy: 0.529411792755127\n",
      "Epoch 200, Loss: 0.01247561164200306, Test Accuracy: 0.529411792755127\n",
      "Epoch 210, Loss: 0.1299557238817215, Test Accuracy: 0.5882353186607361\n",
      "Epoch 220, Loss: 0.002994535258039832, Test Accuracy: 0.5882353186607361\n",
      "Epoch 230, Loss: 0.004769822116941214, Test Accuracy: 0.5882353186607361\n",
      "Epoch 240, Loss: 0.09192231297492981, Test Accuracy: 0.6470588445663452\n",
      "Epoch 250, Loss: 0.04260975122451782, Test Accuracy: 0.6470588445663452\n",
      "Epoch 260, Loss: 0.003935657907277346, Test Accuracy: 0.6470588445663452\n",
      "Epoch 270, Loss: 0.0012155009899288416, Test Accuracy: 0.6470588445663452\n",
      "Epoch 280, Loss: 0.007340952288359404, Test Accuracy: 0.7058823704719543\n",
      "Epoch 290, Loss: 0.08409914374351501, Test Accuracy: 0.7058823704719543\n",
      "Epoch 300, Loss: 0.005316868424415588, Test Accuracy: 0.8235294222831726\n",
      "Epoch 310, Loss: 0.04113175347447395, Test Accuracy: 0.8235294222831726\n",
      "Epoch 320, Loss: 0.08361369371414185, Test Accuracy: 0.8235294222831726\n",
      "Epoch 330, Loss: 0.0013849771348759532, Test Accuracy: 0.8823529481887817\n",
      "Epoch 340, Loss: 0.04175034165382385, Test Accuracy: 0.8823529481887817\n",
      "Epoch 350, Loss: 0.0008733458817005157, Test Accuracy: 0.8823529481887817\n",
      "Epoch 360, Loss: 0.0017361873760819435, Test Accuracy: 0.8823529481887817\n",
      "Epoch 370, Loss: 0.00026751961559057236, Test Accuracy: 0.8823529481887817\n",
      "Epoch 380, Loss: 0.0027903446462005377, Test Accuracy: 0.8823529481887817\n",
      "Epoch 390, Loss: 0.0007771809468977153, Test Accuracy: 0.8823529481887817\n",
      "Epoch 400, Loss: 0.042358119040727615, Test Accuracy: 0.8823529481887817\n",
      "Epoch 410, Loss: 0.0008060981053858995, Test Accuracy: 0.8823529481887817\n",
      "Epoch 420, Loss: 0.04205814003944397, Test Accuracy: 0.8823529481887817\n",
      "Epoch 430, Loss: 0.02165515162050724, Test Accuracy: 0.8823529481887817\n",
      "Epoch 440, Loss: 0.0008617616258561611, Test Accuracy: 0.8823529481887817\n",
      "Epoch 450, Loss: 0.0014797839103266597, Test Accuracy: 0.8823529481887817\n",
      "Epoch 460, Loss: 0.001072688726708293, Test Accuracy: 0.8823529481887817\n",
      "Epoch 470, Loss: 0.12387531250715256, Test Accuracy: 0.8823529481887817\n",
      "Epoch 480, Loss: 0.000824654009193182, Test Accuracy: 0.8823529481887817\n",
      "Epoch 490, Loss: 0.0018203934887424111, Test Accuracy: 0.8823529481887817\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 500\n",
    "best_accuracy = 0\n",
    "for epoch in range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model((features, adj), training=True)\n",
    "        loss_value = loss_fn(labels[train_mask], logits[train_mask])\n",
    "    \n",
    "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    # Compute test accuracy\n",
    "    logits = model((features, adj), training=False)\n",
    "    predictions = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "    correct_predictions = tf.equal(predictions[test_mask], labels[test_mask])\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32)).numpy()\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss_value.numpy()}, Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "dd9f66e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 0.8823529481887817\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final Test Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded7289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6acca82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d12e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994dfdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c65c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06f31ac4",
   "metadata": {},
   "source": [
    "<a name=\"annex\"></a>\n",
    "## <font color='blue'> Annex </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a16f2b",
   "metadata": {},
   "source": [
    "### adjancey matrix\n",
    "\n",
    "To calculate\n",
    "\n",
    "https://networkx.org/documentation/stable/reference/generated/networkx.linalg.graphmatrix.adjacency_matrix.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87549fac",
   "metadata": {},
   "source": [
    "In graph theory and computer science, an adjacency matrix is a square matrix used to represent a finite graph. The elements of the matrix indicate whether pairs of vertices are adjacent or not in the graph.\n",
    "\n",
    "In the special case of a finite simple graph, the adjacency matrix is a (0,1)-matrix with zeros on its diagonal. If the graph is undirected (i.e. all of its edges are bidirectional), the adjacency matrix is symmetric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6eab7dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 1., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 1., 1.],\n",
       "       [0., 0., 1., ..., 1., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adj = nx.adjacency_matrix(G).astype(np.float32)\n",
    "adj = (nx.adjacency_matrix(G) > 0).astype(np.float32)\n",
    "adj.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bb473030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will ensure the matrix represents only connections (1) or no connection (0). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea870648",
   "metadata": {},
   "source": [
    "A self-loop is an edge that connects a node to itself. In an adjacency matrix, self-loops appear as 1s on the diagonal (i.e., adj[i, i] = 1).\n",
    "\n",
    "the Karate Club graph (nx.karate_club_graph()) does not include self-loops by default. The adjacency matrix for this dataset initially has only 0s on the diagonal.\n",
    "\n",
    "Why Add Self-Loops?\n",
    "In Graph Convolutional Networks (GCNs), self-loops are often added because:\n",
    "\n",
    "They allow each node to keep some of its original features in the message-passing process.\n",
    "They stabilize learning by preventing nodes from relying only on their neighbors' featur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e9eb28b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 1., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sp.eye(adj.shape[0]) creates an identity matrix of the same size as adj, \n",
    "#meaning 1s on the diagonal and 0s elsewhere.\n",
    "#Adding it to adj ensures that every node has a self-loop.\n",
    "\n",
    "\n",
    "adj += sp.eye(adj.shape[0])  # Add self-loops\n",
    "adj.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e393e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that now we have 1s in the diagonbal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0faca0a",
   "metadata": {},
   "source": [
    "This code normalizes the adjacency matrix using the Symmetric Normalized Laplacian:\n",
    "    \n",
    "$$\n",
    "\\tilde{A} = D^{-\\frac{1}{2}} A D^{-\\frac{1}{2}}\n",
    "$$\n",
    "\n",
    "- A is the adjancey matrix\n",
    "- D is the degree matrix\n",
    "- D**(-1/2) is the inverse square root of D.\n",
    "\n",
    "\n",
    "The degree matrix D is a diagonal matrix where each diagonl entry Dii represents the degree (number of connections) of node i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "99fe877e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(34, 34), dtype=float32, numpy=\n",
       "array([[0.05882353, 0.0766965 , 0.07312724, ..., 0.09166985, 0.        ,\n",
       "        0.        ],\n",
       "       [0.0766965 , 0.1       , 0.09534626, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.07312724, 0.09534626, 0.09090909, ..., 0.        , 0.0836242 ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.09166985, 0.        , 0.        , ..., 0.14285715, 0.10482848,\n",
       "        0.08908708],\n",
       "       [0.        , 0.        , 0.0836242 , ..., 0.10482848, 0.07692308,\n",
       "        0.06537204],\n",
       "       [0.        , 0.        , 0.        , ..., 0.08908708, 0.06537204,\n",
       "        0.05555556]], dtype=float32)>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree_matrix = np.array(adj.sum(axis=1)).flatten()\n",
    "D_inv_sqrt = np.diag(1.0 / np.sqrt(degree_matrix))\n",
    "adj_normalized = D_inv_sqrt @ adj @ D_inv_sqrt\n",
    "adj = tf.convert_to_tensor(adj_normalized, dtype=tf.float32)\n",
    "\n",
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d3579d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "097e7165",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "385b63d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_features = np.eye(num_nodes, dtype=np.float32)\n",
    "one_hot_features # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b9129b",
   "metadata": {},
   "source": [
    "This creates a one-hot encoded feature matrix for a graph with num_nodes nodes. Each node is represented by a one-hot vector, meaning:\n",
    "\n",
    "Each row corresponds to a node\n",
    "Each column is a unique feature for that node\n",
    "Only one element per row is 1, the rest are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b0c6185e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34, 1),\n",
       " array([[16.],\n",
       "        [ 9.],\n",
       "        [10.],\n",
       "        [ 6.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 4.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 1.],\n",
       "        [ 2.],\n",
       "        [ 5.],\n",
       "        [ 2.],\n",
       "        [ 2.],\n",
       "        [ 2.],\n",
       "        [ 2.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 2.],\n",
       "        [ 2.],\n",
       "        [ 2.],\n",
       "        [ 5.],\n",
       "        [ 3.],\n",
       "        [ 3.],\n",
       "        [ 2.],\n",
       "        [ 4.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 4.],\n",
       "        [ 6.],\n",
       "        [12.],\n",
       "        [17.]], dtype=float32))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This computes the degree of each node in the graph G and stores it as a column vector\n",
    "degrees = np.array([G.degree(n) for n in G.nodes()], dtype=np.float32).reshape(-1, 1)\n",
    "degrees.shape, degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "44c8c47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34, 1),\n",
       " array([[0.15      ],\n",
       "        [0.33333334],\n",
       "        [0.24444444],\n",
       "        [0.6666667 ],\n",
       "        [0.6666667 ]], dtype=float32))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.cluster.clustering.html#networkx.algorithms.cluster.clustering\n",
    "# This computes the clustering coefficient for each node in the graph G and stores it as a column vector\n",
    "\n",
    "clustering_coeffs = np.array([nx.clustering(G, n) for n in G.nodes()], dtype=np.float32).reshape(-1, 1)\n",
    "clustering_coeffs.shape, clustering_coeffs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47561c22",
   "metadata": {},
   "source": [
    "The clustering coefficient of a node measures how tightly connected its neighbors are. \n",
    "\n",
    "https://en.wikipedia.org/wiki/Clustering_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c3cc533d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34, 1),\n",
       " array([[0.43763527],\n",
       "        [0.05393669],\n",
       "        [0.1436568 ],\n",
       "        [0.01190927],\n",
       "        [0.00063131]], dtype=float32))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This computes the betweenness centrality for each node in the graph G and stores it as a column vector\n",
    "betweenness = np.array(list(nx.betweenness_centrality(G).values()), dtype=np.float32).reshape(-1, 1)\n",
    "\n",
    "betweenness.shape, betweenness[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b58fe7",
   "metadata": {},
   "source": [
    "Betweenness centrality measures how often a node appears on the shortest paths between other nodes.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Betweenness_centrality\n",
    "\n",
    "https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.betweenness_centrality.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "13d96a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34, 1),\n",
       " array([[0.08850808],\n",
       "        [0.05741484],\n",
       "        [0.06276686],\n",
       "        [0.03721208],\n",
       "        [0.02050398]], dtype=float32))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This computes the PageRank score for each node in the graph G and stores it as a column vector\n",
    "pagerank = np.array(list(nx.pagerank(G).values()), dtype=np.float32).reshape(-1, 1)\n",
    "pagerank.shape, pagerank[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd7b9d1",
   "metadata": {},
   "source": [
    "PageRank is an algorithm that measures the importance of nodes in a graph, originally designed for ranking web pages.\n",
    "\n",
    "https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9822b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86f92e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb549f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab3da64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f6bf07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ed3ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2251ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "### USe of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "74900165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output:\n",
      " [[1.4336157 0.9010961]\n",
      " [2.4710479 1.7270117]\n",
      " [1.8811625 1.0903105]\n",
      " [1.6412334 1.0542084]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "\n",
    "# Define model\n",
    "input_features = Input(shape=(3,))  # Input node features (3 features per node)\n",
    "input_adj = Input(shape=(4,))  # Adjacency matrix row (for each node)\n",
    "\n",
    "output = GCNLayer(units=2, activation='relu')([input_features, input_adj])\n",
    "model = Model(inputs=[input_features, input_adj], outputs=output)\n",
    "\n",
    "# Run the model\n",
    "output = model([features, adj])\n",
    "print(\"Model Output:\\n\", output.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f1d880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d67a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713b1f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c109156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeb6619b",
   "metadata": {},
   "source": [
    "## references\n",
    "\n",
    "https://en.wikipedia.org/wiki/Adjacency_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
