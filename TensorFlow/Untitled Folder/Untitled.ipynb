{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c1415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebab631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567ee1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38379846",
   "metadata": {},
   "source": [
    "https://jonathan-hui.medium.com/tensorflow-eager-execution-v-s-graph-tf-function-6edaa870b1f1\n",
    "\n",
    "by default TF uses eager_execution.... disavantages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05d1b9f",
   "metadata": {},
   "source": [
    "Graph Mode is a powerful feature where your computations are first defined as a computation graph before being executed. This mode is used primarily in TensorFlow 1.x and still available in TensorFlow 2.x through @tf.function.\n",
    "\n",
    "Key benefits:\n",
    "\n",
    "- Performance Optimization: Since the graph is static, TensorFlow can apply various optimizations like constant folding, kernel fusion, etc., improving execution speed.\n",
    "\n",
    "- Deployment Efficiency: Graphs can be serialized, exported, and run on different platforms (e.g., mobile devices, TPU, etc.).\n",
    "\n",
    "- Parallel Execution: The static graph enables parallel computation across devices efficiently.\n",
    "\n",
    "- Error Checking: Graphs are analyzed before execution, allowing TensorFlow to catch potential issues early.\n",
    "\n",
    "\n",
    "For debugging or quick prototyping, Eager Execution is generally more intuitive, but Graph Mode excels in production scenarios requiring efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eaf246",
   "metadata": {},
   "source": [
    "Graph Mode: When you use @tf.function, TensorFlow traces the function once (using a sample input or the first value you provide), creating a static computation graph. This graph includes all operations needed for forward and backward passes (like matrix multiplications, activations, gradients, etc.). It doesn’t dynamically change once traced — meaning the structure is fixed, but the values computed during the forward and backward passes will depend on the input data and current model parameters.\n",
    "\n",
    "Eager Execution: When not using @tf.function, TensorFlow operates in eager execution mode, which means that operations are evaluated immediately as you run the code, and the graph is built dynamically as the operations are executed. This allows for more flexibility but is slower than graph execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6db4a5",
   "metadata": {},
   "source": [
    "-> SIMPLE EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b3b046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 16:54:56.394291: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-27 16:54:56.394496: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-27 16:54:56.558356: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-27 16:54:56.933005: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-27 16:54:59.116565: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "241e9963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(8, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "@tf.function  # Converts to Graph Mode\n",
    "def add_tensors(x, y):\n",
    "    return x + y\n",
    "\n",
    "# Example usage\n",
    "a = tf.constant(3)\n",
    "b = tf.constant(5)\n",
    "print(add_tensors(a, b))  # Output: 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e4fa71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__add_tensors(x, y):\n",
      "    with ag__.FunctionScope('add_tensors', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.ld(x) + ag__.ld(y)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See what the generated code looks like\n",
    "print(tf.autograph.to_code(add_tensors.python_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d97c14bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# watch the graph using tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64cdb142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Define your function with @tf.function to enable graph mode\n",
    "@tf.function\n",
    "def add_tensors(x, y):\n",
    "    return x + y\n",
    "\n",
    "# Create a directory for TensorBoard logs\n",
    "log_dir = \"logs/graph\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Create a SummaryWriter to log the graph\n",
    "writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "# Log the graph to the writer\n",
    "with writer.as_default():\n",
    "    # Log the graph using tf.summary.trace_on() and tf.summary.trace_export()\n",
    "    tf.summary.trace_on(graph=True)\n",
    "    a = tf.constant(3)\n",
    "    b = tf.constant(5)\n",
    "    add_tensors(a, b)\n",
    "    tf.summary.trace_export(name=\"model_trace\", step=0, profiler_outdir=log_dir)\n",
    "\n",
    "# Start TensorBoard (in the terminal or an IDE with TensorBoard support)\n",
    "# Run the following in your terminal:\n",
    "# tensorboard --logdir=logs/graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5bf44f",
   "metadata": {},
   "source": [
    "Open http://localhost:6006 in your browser to view the graph under the Graph tab in TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7d0cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e68bc74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1da564ab",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "Control flow statements which are very intuitive to write in eager mode can look very complex in graph mode. You can see that in the next examples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14bd5954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__f(x):\n",
      "    with ag__.FunctionScope('f', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (x,)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal x\n",
      "            (x,) = vars_\n",
      "\n",
      "        def if_body():\n",
      "            nonlocal x\n",
      "            x = ag__.ld(x) * ag__.ld(x)\n",
      "\n",
      "        def else_body():\n",
      "            nonlocal x\n",
      "            pass\n",
      "        ag__.if_stmt(ag__.ld(x) > 12, if_body, else_body, get_state, set_state, ('x',), 1)\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.ld(x)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# simple function that returns the square if the input is greater than zero\n",
    "@tf.function\n",
    "def f(x):\n",
    "    if x>12:\n",
    "        x = x * x\n",
    "    return x\n",
    "\n",
    "print(tf.autograph.to_code(f.python_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1ca236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5544ee34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225b353e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b305c633",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_197006/4086060191.py\", line 6, in simple_model  *\n        weights = tf.Variable([[0.1, 0.2], [0.3, 0.4]])\n\n    ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([[\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m2.0\u001b[39m]])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msimple_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filey2aqqurw.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__simple_model\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m biases \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mVariable, ([\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.6\u001b[39m],), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m output \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mmatmul, (ag__\u001b[38;5;241m.\u001b[39mld(x), ag__\u001b[38;5;241m.\u001b[39mld(weights)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;241m+\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(biases)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_197006/4086060191.py\", line 6, in simple_model  *\n        weights = tf.Variable([[0.1, 0.2], [0.3, 0.4]])\n\n    ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.\n"
     ]
    }
   ],
   "source": [
    "# esto da error\n",
    "import tensorflow as tf\n",
    "\n",
    "@tf.function\n",
    "def simple_model(x):\n",
    "    weights = tf.Variable([[0.1, 0.2], [0.3, 0.4]])\n",
    "    biases = tf.Variable([0.5, 0.6])\n",
    "    output = tf.matmul(x, weights) + biases\n",
    "    return tf.nn.relu(output)\n",
    "\n",
    "# Example input data\n",
    "x = tf.constant([[1.0, 2.0]])\n",
    "\n",
    "# Forward pass\n",
    "print(simple_model(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5880ee96",
   "metadata": {},
   "source": [
    "The error occurs because TensorFlow's @tf.function decorator requires that tf.Variable objects are created outside the decorated function or only once during the first call. When you define weights and biases inside the @tf.function-decorated function, TensorFlow tries to recreate these variables every time the function is called, which is not allowed.\n",
    "\n",
    "To fix this, you need to create the tf.Variable objects once, outside of the function, and then use them inside the @tf.function function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc1fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "803188c2",
   "metadata": {},
   "source": [
    "in the following:\n",
    "    \n",
    "The structure of the graph is defined once when you call simple_model(x) for the first time.\n",
    "\n",
    "Values like x, weights, and biases will change as you pass new data during training.\n",
    "\n",
    "The graph stays the same, but the values for activations and gradients will change depending on the data and current model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a6979c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1.2 1.6]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the model with tf.function\n",
    "@tf.function\n",
    "def simple_model(x, weights, biases):\n",
    "    output = tf.matmul(x, weights) + biases\n",
    "    return tf.nn.relu(output)\n",
    "\n",
    "# Create variables outside the tf.function\n",
    "weights = tf.Variable([[0.1, 0.2], [0.3, 0.4]])\n",
    "biases = tf.Variable([0.5, 0.6])\n",
    "\n",
    "# Example input data\n",
    "x = tf.constant([[1.0, 2.0]])\n",
    "\n",
    "# Forward pass\n",
    "print(simple_model(x, weights, biases))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fbf7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbbada0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57fb6e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divisible by 4 and 6\n",
      "1\n",
      "2\n",
      "3\n",
      "Divisible by 4\n",
      "5\n",
      "Divisible by 6\n",
      "7\n",
      "Divisible by 4\n",
      "9\n",
      "def tf__check_divisibility(max_num):\n",
      "    with ag__.FunctionScope('check_divisibility', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "        counter = 0\n",
      "\n",
      "        def get_state_3():\n",
      "            return (counter,)\n",
      "\n",
      "        def set_state_3(vars_):\n",
      "            nonlocal counter\n",
      "            (counter,) = vars_\n",
      "\n",
      "        def loop_body(itr):\n",
      "            nonlocal counter\n",
      "            num = itr\n",
      "\n",
      "            def get_state_2():\n",
      "                return ()\n",
      "\n",
      "            def set_state_2(block_vars):\n",
      "                pass\n",
      "\n",
      "            def if_body_2():\n",
      "                ag__.ld(print)('Divisible by 4 and 6')\n",
      "\n",
      "            def else_body_2():\n",
      "\n",
      "                def get_state_1():\n",
      "                    return ()\n",
      "\n",
      "                def set_state_1(block_vars):\n",
      "                    pass\n",
      "\n",
      "                def if_body_1():\n",
      "                    ag__.ld(print)('Divisible by 4')\n",
      "\n",
      "                def else_body_1():\n",
      "\n",
      "                    def get_state():\n",
      "                        return ()\n",
      "\n",
      "                    def set_state(block_vars):\n",
      "                        pass\n",
      "\n",
      "                    def if_body():\n",
      "                        ag__.ld(print)('Divisible by 6')\n",
      "\n",
      "                    def else_body():\n",
      "                        ag__.ld(print)(ag__.ld(num))\n",
      "                    ag__.if_stmt(ag__.ld(num) % 6 == 0, if_body, else_body, get_state, set_state, (), 0)\n",
      "                ag__.if_stmt(ag__.ld(num) % 4 == 0, if_body_1, else_body_1, get_state_1, set_state_1, (), 0)\n",
      "            ag__.if_stmt(ag__.and_(lambda : ag__.ld(num) % 4 == 0, lambda : ag__.ld(num) % 6 == 0), if_body_2, else_body_2, get_state_2, set_state_2, (), 0)\n",
      "            counter = ag__.ld(counter)\n",
      "            counter += 1\n",
      "        num = ag__.Undefined('num')\n",
      "        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(max_num),), None, fscope), None, loop_body, get_state_3, set_state_3, ('counter',), {'iterate_names': 'num'})\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.ld(counter)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# divisible by 4, 6 or both\n",
    "\n",
    "@tf.function\n",
    "def check_divisibility(max_num):\n",
    "    counter = 0\n",
    "    for num in range(max_num):\n",
    "        if num % 4 == 0 and num % 6 == 0:\n",
    "            print('Divisible by 4 and 6')\n",
    "        elif num % 4 == 0:\n",
    "            print('Divisible by 4')\n",
    "        elif num % 6 == 0:\n",
    "            print('Divisible by 6')\n",
    "        else:\n",
    "            print(num)\n",
    "        counter += 1\n",
    "    return counter\n",
    "\n",
    "# Example usage\n",
    "check_divisibility(10)\n",
    "\n",
    "# Print the code representation of the graph\n",
    "print(tf.autograph.to_code(check_divisibility.python_function))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8922569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1f1362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690a2721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7106e2d5",
   "metadata": {},
   "source": [
    "## PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7177e27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced with 2\n",
      "Traced with 2\n",
      "Traced with 2\n",
      "Traced with 2\n",
      "Traced with 2\n",
      "Traced with 3\n"
     ]
    }
   ],
   "source": [
    "## print\n",
    "def f(x):\n",
    "    print(\"Traced with\", x)\n",
    "\n",
    "for i in range(5):\n",
    "    f(2)\n",
    "    \n",
    "f(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6708e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced with 2\n",
      "Traced with 3\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "    print(\"Traced with\", x)\n",
    "\n",
    "for i in range(5):\n",
    "    f(2)\n",
    "    \n",
    "f(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f1d0f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced with 2\n",
      "Executed with 2\n",
      "Executed with 2\n",
      "Executed with 2\n",
      "Executed with 2\n",
      "Executed with 2\n",
      "Traced with 3\n",
      "Executed with 3\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "    print(\"Traced with\", x)\n",
    "    # added tf.print\n",
    "    tf.print(\"Executed with\", x)\n",
    "\n",
    "for i in range(5):\n",
    "    f(2)\n",
    "    \n",
    "f(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633a8e4d",
   "metadata": {},
   "source": [
    "tf.print is graph aware and will run as expected in loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49896709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0288a692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a866230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01b9811d",
   "metadata": {},
   "source": [
    "Summary of Key Benefits:\n",
    "Performance Boost: Faster execution through optimization, better memory management, and reduced Python overhead.\n",
    "\n",
    "Hardware Optimization: Efficient execution on GPUs/TPUs with hardware-specific optimizations.\n",
    "\n",
    "Portability: Easier deployment and execution across different platforms and hardware.\n",
    "\n",
    "Reduced Python Overhead: Compiles operations into a static graph, eliminating the need for repeated function calls in Python.\n",
    "\n",
    "Efficient Backpropagation: Optimized gradient computation, leading to faster training.\n",
    "\n",
    "By using @tf.function, you're enabling TensorFlow to optimize execution for performance, which is especially important for complex models and large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3caa5227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with no graph mode took 13.6618 seconds.\n",
      "Training with graph mode took 1.1947 seconds.\n",
      "Speedup from graph mode: 11.44x\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Define a simple model for binary classification\n",
    "class SimpleModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        return self.dense2(x)\n",
    "\n",
    "# Loss and optimization functions\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Generate random data for training (1000 samples, 20 features)\n",
    "X_train = np.random.randn(1000, 20).astype(np.float32)\n",
    "y_train = np.random.randint(0, 2, size=(1000, 1)).astype(np.float32)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Training step without @tf.function\n",
    "def train_step_no_graph(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(y, logits)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# Training step with @tf.function (graph mode)\n",
    "@tf.function\n",
    "def train_step_with_graph(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(y, logits)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# Helper function to train for one epoch\n",
    "def train_epoch(train_data, train_labels, train_step_fn):\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in zip(train_data, train_labels):\n",
    "        # Ensure x_batch has the correct shape (batch_size, num_features)\n",
    "        if x_batch.ndim == 1:\n",
    "            x_batch = np.expand_dims(x_batch, axis=0)\n",
    "        # Ensure y_batch has the correct shape (batch_size, 1)\n",
    "        if y_batch.ndim == 1:\n",
    "            y_batch = np.expand_dims(y_batch, axis=0)\n",
    "        loss = train_step_fn(x_batch, y_batch)\n",
    "        total_loss += loss\n",
    "    return total_loss / len(train_data)\n",
    "\n",
    "# Fix the input shape by ensuring X_train has a batch dimension\n",
    "if X_train.ndim == 1:\n",
    "    X_train = X_train.reshape(-1, 20)  # Ensures input is (batch_size, 20)\n",
    "\n",
    "# Train with no graph mode (normal Python function)\n",
    "start_time = time.time()\n",
    "train_epoch(X_train, y_train, train_step_no_graph)\n",
    "end_time = time.time()\n",
    "no_graph_duration = end_time - start_time\n",
    "print(f\"Training with no graph mode took {no_graph_duration:.4f} seconds.\")\n",
    "\n",
    "# Train with graph mode (tf.function)\n",
    "start_time = time.time()\n",
    "train_epoch(X_train, y_train, train_step_with_graph)\n",
    "end_time = time.time()\n",
    "graph_duration = end_time - start_time\n",
    "print(f\"Training with graph mode took {graph_duration:.4f} seconds.\")\n",
    "\n",
    "# Compare the results\n",
    "print(f\"Speedup from graph mode: {no_graph_duration / graph_duration:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1130f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
