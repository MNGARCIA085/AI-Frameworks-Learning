{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b4e6e7",
   "metadata": {},
   "source": [
    "CUSTOM LAYERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6ed612",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f71b8728",
   "metadata": {},
   "source": [
    "INTRO\n",
    "\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfff047a",
   "metadata": {},
   "source": [
    "SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c613281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43131d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b91ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b12d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da95b663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "933fdda8",
   "metadata": {},
   "source": [
    "## CUSTOM LAMBDA LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usaremos una lambnda layer que dará como salida el valor absoluto del resultado\n",
    "\n",
    "# primero, modelo soin lambda y evamps su salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bad92a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Input: [[-1.  2. -3.]]\n",
      "Output without Lambda layer: [[ 0.0606966  -2.374105   -0.30891085]]\n",
      "Output with Lambda layer: [[3.95626   2.865855  1.4252148]]\n"
     ]
    }
   ],
   "source": [
    "# Define a simple model without Lambda layer\n",
    "model_without_lambda = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(3,)),  # Input shape with 3 features\n",
    "    tf.keras.layers.Dense(3)  # Simple dense layer\n",
    "])\n",
    "\n",
    "# Define a model with Lambda layer applied to output\n",
    "model_with_lambda = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(3,)),\n",
    "    tf.keras.layers.Dense(3),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.abs(x))\n",
    "])\n",
    "\n",
    "# Create test input\n",
    "test_input = np.array([[-1.0, 2.0, -3.0]])\n",
    "\n",
    "# Run inference\n",
    "output_without_lambda = model_without_lambda.predict(test_input)\n",
    "output_with_lambda = model_with_lambda.predict(test_input)\n",
    "\n",
    "print(\"Input:\", test_input)\n",
    "print(\"Output without Lambda layer:\", output_without_lambda)\n",
    "print(\"Output with Lambda layer:\", output_with_lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ee592",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0760042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Input: [[-1.  2. -3.]]\n",
      "Output without Lambda layer: [[ 1.5527086 -2.6101239 -2.6486883]]\n",
      "Output with Lambda layer: [[-11.29807  -20.425661 -18.738115]]\n"
     ]
    }
   ],
   "source": [
    "# Define a simple model without Lambda layer\n",
    "model_without_lambda = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(3,)),  # Input shape with 3 features\n",
    "    tf.keras.layers.Dense(3)  # Simple dense layer\n",
    "])\n",
    "\n",
    "# Define a model with Lambda layer applied to output\n",
    "model_with_lambda = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(3,)),\n",
    "    tf.keras.layers.Dense(3),\n",
    "    tf.keras.layers.Lambda(lambda x: x * 10)\n",
    "])\n",
    "\n",
    "# Create test input\n",
    "test_input = np.array([[-1.0, 2.0, -3.0]])\n",
    "\n",
    "# Run inference\n",
    "output_without_lambda = model_without_lambda.predict(test_input)\n",
    "output_with_lambda = model_with_lambda.predict(test_input)\n",
    "\n",
    "print(\"Input:\", test_input)\n",
    "print(\"Output without Lambda layer:\", output_without_lambda)\n",
    "print(\"Output with Lambda layer:\", output_with_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef25322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a50f8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "Output with Lambda layer: [[0.14764886 0.05773554 0.15037133 0.07073749 0.1440041  0.1030826\n",
      "  0.06780919 0.13017373 0.05642467 0.07201242]]\n"
     ]
    }
   ],
   "source": [
    "# Define a custom Leaky ReLU function\n",
    "def my_leaky_relu(x):\n",
    "    return K.maximum(0.1 * x, x)\n",
    "\n",
    "\n",
    "# Define a model with Lambda layer applying Leaky ReLU\n",
    "model_with_lambda = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.Lambda(my_leaky_relu),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Create test input\n",
    "test_input = np.random.rand(1, 28, 28)  # Random input\n",
    "\n",
    "# Run inference\n",
    "output_with_lambda = model_with_lambda.predict(test_input)\n",
    "\n",
    "\n",
    "print(\"Output with Lambda layer:\", output_with_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6e50a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 2.4302 - accuracy: 0.0990\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2.2975 - accuracy: 0.1500\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2.2305 - accuracy: 0.1980\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2.2036 - accuracy: 0.2110\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2.1252 - accuracy: 0.2450\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Output with Lambda layer: [[0.10284878 0.15264723 0.26062122 0.04645119 0.09344871 0.05763418\n",
      "  0.02753688 0.16007082 0.03259027 0.06615072]]\n"
     ]
    }
   ],
   "source": [
    "# including training!!!\n",
    "# Define a custom Leaky ReLU function\n",
    "def my_leaky_relu(x):\n",
    "    return K.maximum(0.1 * x, x)\n",
    "\n",
    "\n",
    "# Define a model with Lambda layer applying Leaky ReLU\n",
    "model_with_lambda = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.Lambda(my_leaky_relu),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile models\n",
    "model_with_lambda.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create fake training data\n",
    "x_train = np.random.rand(1000, 28, 28)\n",
    "y_train = np.random.randint(0, 10, 1000)\n",
    "\n",
    "# Train models\n",
    "model_with_lambda.fit(x_train, y_train, epochs=5, batch_size=32, verbose=1)\n",
    "\n",
    "# Create test input\n",
    "test_input = np.random.rand(1, 28, 28)  # Random input\n",
    "\n",
    "# Run inference\n",
    "output_with_lambda = model_with_lambda.predict(test_input)\n",
    "\n",
    "print(\"Output with Lambda layer:\", output_with_lambda)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b30027c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e43f97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80e55924",
   "metadata": {},
   "source": [
    "## CUSTOM DENSE LAYER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47606a9",
   "metadata": {},
   "source": [
    "we'll walk through how to create a custom layer that inherits the Layer class. Unlike simple Lambda layers you did previously, the custom layer here will contain weights that can be updated during training.\n",
    "\n",
    "Custom LAyer with weights\n",
    "\n",
    "To make a custom layer that is trainable, we need to define a class that inherits the Layer base class from Keras. \n",
    "\n",
    "This class requires three functions: \n",
    "__init__(), \n",
    "build()\n",
    "call(). \n",
    "\n",
    "These ensure that our custom layer has a state and computation that can be accessed during training or inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29acd0bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1649184921.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [17], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __init__(self, ...):\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class CustomLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, ...):  \n",
    "        super(CustomLayer, self).__init__(...)\n",
    "        # Initialize attributes\n",
    "\n",
    "    def build(self, input_shape):  \n",
    "        # Define layer's weights\n",
    "        self.some_weight = self.add_weight(...)\n",
    "\n",
    "    def call(self, inputs):  \n",
    "        # Define the forward pass\n",
    "        return some_transformation(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b570e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# inherit from this base class\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class SimpleDense(Layer):\n",
    "    def __init__(self, units=32):\n",
    "        '''Initializes the instance attributes'''\n",
    "        super(SimpleDense, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        '''Create the state of the layer (weights)'''\n",
    "        # Initialize the weights\n",
    "        self.w = self.add_weight(name=\"kernel\",\n",
    "                                 shape=(input_shape[-1], self.units),\n",
    "                                 initializer=tf.random_normal_initializer(),\n",
    "                                 trainable=True)\n",
    "\n",
    "        # Initialize the biases\n",
    "        self.b = self.add_weight(name=\"bias\",\n",
    "                                 shape=(self.units,),\n",
    "                                 initializer=tf.zeros_initializer(),\n",
    "                                 trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        '''Defines the computation from inputs to outputs'''\n",
    "        return tf.matmul(inputs, self.w) + self.b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d29c7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'simple_dense_2/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[-0.10361432]], dtype=float32)>, <tf.Variable 'simple_dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# declare an instance of the class\n",
    "my_dense = SimpleDense(units=1)\n",
    "\n",
    "# define an input and feed into the layer\n",
    "x = tf.ones((1, 1))\n",
    "y = my_dense(x)\n",
    "\n",
    "# parameters of the base Layer class like `variables` can be used\n",
    "print(my_dense.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d6ec22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "[[18.981771]]\n"
     ]
    }
   ],
   "source": [
    "# Define dataset (reshape to 2D: (samples, features))\n",
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float).reshape(-1, 1)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float).reshape(-1, 1)\n",
    "\n",
    "# Create and compile model\n",
    "my_layer = SimpleDense(units=1)\n",
    "model = tf.keras.Sequential([my_layer])\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "# Train model\n",
    "model.fit(xs, ys, epochs=500, verbose=0)\n",
    "\n",
    "# Perform inference\n",
    "print(model.predict([[10.0]]))  # Reshaped input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a38cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another custom layer .> quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcaaaeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "Input: [[ 1. -2.  3.]]\n",
      "Output: [[1. 4. 9.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class SquareLayer(Layer):\n",
    "    def __init__(self):\n",
    "        super(SquareLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.square(inputs)\n",
    "\n",
    "# Example usage\n",
    "import numpy as np\n",
    "\n",
    "# Create a model with the custom layer\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(3,)),  \n",
    "    SquareLayer()\n",
    "])\n",
    "\n",
    "# Test the layer with sample input\n",
    "test_input = np.array([[1.0, -2.0, 3.0]])\n",
    "output = model.predict(test_input)\n",
    "\n",
    "print(\"Input:\", test_input)\n",
    "print(\"Output:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6d97aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5659e89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "Test Input: [[5.]]\n",
      "Predicted Output: [[15.]]\n",
      "Learned Scale Factor: [3.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "\n",
    "#  learns a scalar weight that multiplies the input; scale is the weight\n",
    "# well initilaizar it with 1\n",
    "\n",
    "class ScaleLayer(Layer):\n",
    "    def __init__(self, initial_scale=1.0):\n",
    "        super(ScaleLayer, self).__init__()\n",
    "        self.initial_scale = initial_scale\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Trainable scalar weight\n",
    "        self.scale = self.add_weight(\n",
    "            name=\"scale\",\n",
    "            shape=(1,),\n",
    "            initializer=tf.constant_initializer(self.initial_scale),\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs * self.scale\n",
    "\n",
    "# Create fake dataset (y = 3 * x)\n",
    "x_train = np.random.rand(1000, 1).astype(np.float32) * 10\n",
    "y_train = 3 * x_train  \n",
    "\n",
    "# Create model with the custom layer\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),\n",
    "    ScaleLayer(initial_scale=1.0)  # Trainable scaling factor\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=100, verbose=0)\n",
    "\n",
    "# Test the model\n",
    "test_input = np.array([[5.0]], dtype=np.float32)\n",
    "output = model.predict(test_input)\n",
    "\n",
    "print(\"Test Input:\", test_input)\n",
    "print(\"Predicted Output:\", output)\n",
    "print(\"Learned Scale Factor:\", model.layers[0].get_weights()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "875dcd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "Test Input: [[15.]]\n",
      "Predicted Output: [[45.]]\n",
      "Learned Scale Factor: [3.]\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_input = np.array([[15.0]], dtype=np.float32)\n",
    "output = model.predict(test_input)\n",
    "\n",
    "print(\"Test Input:\", test_input)\n",
    "print(\"Predicted Output:\", output)\n",
    "print(\"Learned Scale Factor:\", model.layers[0].get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eddfd0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce87da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e641b940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f40ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c64727eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "# Define the custom quadratic layer\n",
    "class SimpleQuadratic(Layer):\n",
    "    def __init__(self, units=32, activation=None):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        a_init = tf.random_normal_initializer()\n",
    "        b_init = tf.random_normal_initializer()\n",
    "        c_init = tf.zeros_initializer()\n",
    "        self.a = self.add_weight(shape=(input_shape[-1], self.units), initializer=a_init, trainable=True, name=\"a\")\n",
    "        self.b = self.add_weight(shape=(input_shape[-1], self.units), initializer=b_init, trainable=True, name=\"b\")\n",
    "        self.c = self.add_weight(shape=(self.units,), initializer=c_init, trainable=True, name=\"c\")\n",
    "   \n",
    "    def call(self, inputs):\n",
    "        x_squared = tf.math.square(inputs)\n",
    "        x_squared_times_a = tf.linalg.matmul(x_squared, self.a)\n",
    "        x_times_b = tf.linalg.matmul(inputs, self.b)\n",
    "        output = x_squared_times_a + x_times_b + self.c\n",
    "        return self.activation(output) if self.activation else output  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4939dbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 19:20:25.783302: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2754 - accuracy: 0.9192\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1359 - accuracy: 0.9581\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1041 - accuracy: 0.9677\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0840 - accuracy: 0.9734\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0741 - accuracy: 0.9762\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0756 - accuracy: 0.9779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0755547285079956, 0.9779000282287598]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  SimpleQuadratic(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e878a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# podría comparar con y sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab9da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d473c239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4cfe39a",
   "metadata": {},
   "source": [
    "### ACTIVATION IN CUSTOM LAYERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2682a9",
   "metadata": {},
   "source": [
    "To use the built-in activations in Keras, we can specify an activation parameter in the __init__() method of our custom layer class. From there, we can initialize it by using the tf.keras.activations.get() method. This takes in a string identifier that corresponds to one of the available activations in Keras. Next, you can now pass in the forward computation to this activation in the call() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "308da766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "Test Input: [[6.]]\n",
      "Predicted Output: [[11.929941]]\n",
      "Learned Weights: [array([[1.9706826]], dtype=float32), array([0.10584502], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class SimpleDense(Layer):\n",
    "    def __init__(self, units=32, activation=None):\n",
    "        super(SimpleDense, self).__init__()\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(name=\"kernel\",\n",
    "                                 shape=(input_shape[-1], self.units),\n",
    "                                 initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(name=\"bias\",\n",
    "                                 shape=(self.units,),\n",
    "                                 initializer=tf.zeros_initializer(),\n",
    "                                 trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.w) + self.b)\n",
    "\n",
    "# --- Fake Data (Linear Relationship) ---\n",
    "x_train = np.array([[1], [2], [3], [4], [5]], dtype=np.float32)  # Input\n",
    "y_train = np.array([[2], [4], [6], [8], [10]], dtype=np.float32) # Output (y = 2x)\n",
    "\n",
    "# --- Define Model with Custom Layer ---\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),  # Input layer\n",
    "    SimpleDense(units=1, activation=None)  # Custom Dense layer\n",
    "])\n",
    "\n",
    "# --- Train Model ---\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss='mse')\n",
    "model.fit(x_train, y_train, epochs=500, verbose=0)\n",
    "\n",
    "# --- Test Model ---\n",
    "test_input = np.array([[6]], dtype=np.float32)  # Expected output: 12\n",
    "output = model.predict(test_input)\n",
    "\n",
    "print(\"Test Input:\", test_input)\n",
    "print(\"Predicted Output:\", output)\n",
    "print(\"Learned Weights:\", model.layers[0].get_weights())  # Check trained weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c209bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5b4583d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "Test Input: [[6.]]\n",
      "Predicted Output: [[11.941468]]\n",
      "Learned Weights: [array([[1.9755067]], dtype=float32), array([0.08842861], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# now let's try with anothr act\n",
    "\n",
    "# --- Define Model with Custom Layer ---\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),  # Input layer\n",
    "    SimpleDense(units=1, activation='relu')  # Custom Dense layer\n",
    "])\n",
    "\n",
    "# --- Train Model ---\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss='mse')\n",
    "model.fit(x_train, y_train, epochs=500, verbose=0)\n",
    "\n",
    "# --- Test Model ---\n",
    "test_input = np.array([[6]], dtype=np.float32)  # Expected output: 12\n",
    "output = model.predict(test_input)\n",
    "\n",
    "print(\"Test Input:\", test_input)\n",
    "print(\"Predicted Output:\", output)\n",
    "print(\"Learned Weights:\", model.layers[0].get_weights())  # Check trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2915e494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "Test Input: [[6.]]\n",
      "Predicted Output: [[0.99999195]]\n",
      "Learned Weights: [array([[1.8315052]], dtype=float32), array([0.7404167], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# --- Define Model with Custom Layer ---\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),  # Input layer\n",
    "    SimpleDense(units=1, activation='sigmoid')  # Custom Dense layer\n",
    "])\n",
    "\n",
    "# --- Train Model ---\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss='mse')\n",
    "model.fit(x_train, y_train, epochs=500, verbose=0)\n",
    "\n",
    "# --- Test Model ---\n",
    "test_input = np.array([[6]], dtype=np.float32)  # Expected output: 12\n",
    "output = model.predict(test_input)\n",
    "\n",
    "print(\"Test Input:\", test_input)\n",
    "print(\"Predicted Output:\", output)\n",
    "print(\"Learned Weights:\", model.layers[0].get_weights())  # Check trained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52726018",
   "metadata": {},
   "source": [
    "como la sigmoid acota la salida entre 0 y 1 obviamente aqui nos alejamos mucho del valor real (12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c371335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
