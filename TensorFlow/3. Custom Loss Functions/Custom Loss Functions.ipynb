{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f6c3f0d",
   "metadata": {},
   "source": [
    "# <font color='#154360'> <center> CUSTOM LOSS FUNCTIONS </center> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2514eb01",
   "metadata": {},
   "source": [
    "## <font color='blue'> Table of Contents </font>\n",
    "\n",
    "1. [Introduction](#1)\n",
    "2. [Setup](#2)  \n",
    "3. [Basic example](#3)\n",
    "4. [Multi-output model](#4) <br>\n",
    "    4.1. [Helper Functions](#4.1) <br>\n",
    "    4.2. [Data](#4.2) <br>\n",
    "    4.3. [Build, compile, train and evaluate the model](#4.3) <br>\n",
    "    4.4. [Making predictions](#4.4) <br>\n",
    "5. [Siamese Network](#5) <br>\n",
    "    5.1. [Helper Functions](#5.1) <br>\n",
    "    5.2. [Data](#5.2) <br>\n",
    "    5.3. [Model](#5.3) <br>\n",
    "    5.4. [Training](#5.4) <br>\n",
    "    5.5. [Evaluation](#5.5) <br>\n",
    "    5.6. [Making predictions](#5.6) <br>\n",
    "6. [References](#references)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edab98ba",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## <font color='blue'> 1. Introduction </font>\n",
    "\n",
    "This notebook demonstrates how to implement custom loss functions in TensorFlow using a few simple examples. Custom loss functions allow you to tailor model optimization to specific problem requirements, beyond standard loss functions like MSE or cross-entropy.  We'll cover both function-based and class-based implementations, showcasing their flexibility and ease of integration into Keras models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee4845e",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## <font color='blue'> 2. Setup </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86866adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70234a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for NumPy\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9c1b26",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## <font color='blue'> 3. Example 1: Without huperparameters </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8156cf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11730819]\n",
      " [0.12518579]\n",
      " [0.68556529]\n",
      " [0.43030589]\n",
      " [0.20052473]] [3.23461638 3.25037158 4.37113057 3.86061179 3.40104945]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2x+3+epsilon\n",
    "\n",
    "# Generating random X values (100 samples, 1 feature)\n",
    "X = np.random.rand(100, 1)\n",
    "\n",
    "# Calculating y based on the equation: y = 2X + 3 + noise\n",
    "noise = np.random.normal(0, 0.1, X.shape[0])  # Adding Gaussian noise\n",
    "y = 2 * X.sum(axis=1) + 3 #+ noise  # Sum of X features + 3 + noise\n",
    "\n",
    "# Check a few values\n",
    "print(X[:5], y[:5])  # Print first 5 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d47384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd26479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e7a545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e36941f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "# inputs\n",
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "\n",
    "# labels\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82f20adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, very simple because our porblem is very simple\n",
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000ae151",
   "metadata": {},
   "source": [
    "### Custom Loss\n",
    "\n",
    "Now let's see how we can use a custom loss. We first define a function that accepts the ground truth labels (`y_true`) and model predictions (`y_pred`) as parameters. We then compute and return the loss value in the function definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16f5b72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function\n",
    "def my_huber_loss(y_true, y_pred):\n",
    "    threshold = 1\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) <= threshold\n",
    "    small_error_loss = tf.square(error) / 2\n",
    "    big_error_loss = threshold * (tf.abs(error) - (0.5 * threshold))\n",
    "    return tf.where(is_small_error, small_error_loss, big_error_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4328c64",
   "metadata": {},
   "source": [
    "Using the loss function is as simple as specifying the loss function in the `loss` argument of `model.compile()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afb86042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "[[23.034878]]\n"
     ]
    }
   ],
   "source": [
    "# training with custom loss function\n",
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "model.compile(optimizer='sgd', loss=my_huber_loss)\n",
    "model.fit(X, y, epochs=500,verbose=0)\n",
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d27434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f69fc46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1212b2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "[[22.555027]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "model.fit(X, y, epochs=500,verbose=0)\n",
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a0067a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0757770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for that prediction, we get better results with the huber loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b969e004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4f9a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbcfefa0",
   "metadata": {},
   "source": [
    "### clased based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7cee5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "\n",
    "# labels\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "016a3993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, very simple because our porblem is very simple\n",
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d106dbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHuberLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, threshold=1, name=\"my_huber_loss\"):\n",
    "        super().__init__(name=name)\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) <= self.threshold\n",
    "        small_error_loss = tf.square(error) / 2\n",
    "        big_error_loss = self.threshold * (tf.abs(error) - (0.5 * self.threshold))\n",
    "        return tf.where(is_small_error, small_error_loss, big_error_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd239a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x75989a58add0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "[[18.453766]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "model.compile(optimizer='sgd', loss=my_huber_loss)\n",
    "model.fit(xs, ys, epochs=500,verbose=0)\n",
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7769ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c710746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae7b711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fabace36",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## <font color='blue'> 4. Example 2: With huperparameters </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d9b8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(100, 1)\n",
    "y = np.random.rand(100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0af59546",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd5fe1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7da5d716",
   "metadata": {},
   "source": [
    "The `loss` argument in `model.compile()` only accepts functions that accepts two parameters: the ground truth (`y_true`) and the model predictions (`y_pred`). If we want to include a hyperparameter that we can tune, then we can define a wrapper function that accepts this hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60f41887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function that accepts the hyperparameter\n",
    "def my_huber_loss_with_threshold(threshold):\n",
    "  \n",
    "    # function that accepts the ground truth and predictions\n",
    "    def my_huber_loss(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) <= threshold\n",
    "        small_error_loss = tf.square(error) / 2\n",
    "        big_error_loss = threshold * (tf.abs(error) - (0.5 * threshold))\n",
    "        \n",
    "        return tf.where(is_small_error, small_error_loss, big_error_loss) \n",
    "\n",
    "    # return the inner function tuned by the hyperparameter\n",
    "    return my_huber_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45f11d0",
   "metadata": {},
   "source": [
    "We can now specify the `loss` as the wrapper function above. Notice that we can now set the `threshold` value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa6f1dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "[[18.43621]]\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', \n",
    "              loss=my_huber_loss_with_threshold(threshold=1.2))\n",
    "\n",
    "model.fit(xs, ys, epochs=500,verbose=0)\n",
    "\n",
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79a0f882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "[[16.92289]]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "[[13.878433]]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "[[11.500145]]\n"
     ]
    }
   ],
   "source": [
    "# vary the threshold\n",
    "\n",
    "thresholds = [0.8, 1.2, 1.6]\n",
    "\n",
    "\n",
    "for t in thresholds:\n",
    "    model.compile(optimizer='sgd', \n",
    "                  loss=my_huber_loss_with_threshold(threshold=t))\n",
    "\n",
    "    model.fit(X, y, epochs=100,verbose=0)\n",
    "\n",
    "    print(model.predict([10.0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5af27e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e58f89c9",
   "metadata": {},
   "source": [
    "as a class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3057931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import Loss\n",
    "\n",
    "class MyHuberLoss(Loss):\n",
    "  \n",
    "    # initialize instance attributes\n",
    "    def __init__(self, threshold=1):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    # compute loss\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) <= self.threshold\n",
    "        small_error_loss = tf.square(error) / 2\n",
    "        big_error_loss = self.threshold * (tf.abs(error) - (0.5 * self.threshold))\n",
    "        return tf.where(is_small_error, small_error_loss, big_error_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11da8f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 233ms/step\n",
      "[[18.436605]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "model.compile(optimizer='sgd', loss=MyHuberLoss(threshold=1.2))\n",
    "model.fit(xs, ys, epochs=500,verbose=0)\n",
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726084c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
