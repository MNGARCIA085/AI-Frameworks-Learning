{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7f026de",
   "metadata": {},
   "source": [
    "# <div style=\"text-align: center; color: #1a5276;\">Custom Loss</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f20e2f",
   "metadata": {},
   "source": [
    "## <font color='blue'>  Table of Contents </font>\n",
    "\n",
    "1. [Introduction](#1)\n",
    "2. [Setup](#2)\n",
    "3. [Example 1](#3)\n",
    "4. [Example 2](#4)\n",
    "5. [Example 3](#5)\n",
    "6. [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2318260e",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## <font color='blue'> 1. Introduction </font>\n",
    "\n",
    "This notebook demonstrates how to create custom loss functions in PyTorch using simple examples. Custom losses allow you to tailor model optimization to specific goals, which can be crucial for tasks like imbalanced data, specific error penalization, or unique performance metrics. We'll cover the basics and provide practical examples for better understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd11fdde",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## <font color='blue'> 2. Setup </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb9ac0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dfb1f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7268c23fd9f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a71917",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## <font color='blue'> 3. Example 1 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b3b4e",
   "metadata": {},
   "source": [
    "This simplified example defines a custom MSE loss function and compares it with PyTorch's built-in MSE loss to confirm they produce the same result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2ac8ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMSELoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom Mean Squared Error (MSE) Loss.\n",
    "\n",
    "    This custom loss function computes the mean squared error between \n",
    "    predicted values (y_pred) and true values (y_true).\n",
    "\n",
    "    Usage:\n",
    "        loss_fn = CustomMSELoss()\n",
    "        loss = loss_fn(y_pred, y_true)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CustomMSELoss, self).__init__()  # Initialize the parent class (nn.Module).\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Computes the mean squared error loss.\n",
    "\n",
    "        Args:\n",
    "            y_pred (torch.Tensor): Predicted values.\n",
    "            y_true (torch.Tensor): Ground truth values.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The calculated MSE loss.\n",
    "        \"\"\"\n",
    "        return torch.mean((y_pred - y_true) ** 2)  # Element-wise squared difference, then mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b74841d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2877, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "y_pred = torch.randn(5, 1, requires_grad=True)\n",
    "y_true = torch.randn(5, 1)\n",
    "\n",
    "# Custom MSE\n",
    "custom_mse = CustomMSELoss()(y_pred, y_true)\n",
    "\n",
    "custom_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0590560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now we will see if we get the same results using the PyTorch built-in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48526f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom MSE: 0.287668\n",
      "Built-in MSE: 0.287668\n"
     ]
    }
   ],
   "source": [
    "# PyTorch built-in MSE\n",
    "builtin_mse = F.mse_loss(y_pred, y_true)\n",
    "\n",
    "print(f\"Custom MSE: {custom_mse.item():.6f}\")\n",
    "print(f\"Built-in MSE: {builtin_mse.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc29db0b",
   "metadata": {},
   "source": [
    "As expected, we get the same results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f1a4b2",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## <font color='blue'> 4. Example 2 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96357e83",
   "metadata": {},
   "source": [
    "This custom loss function combines binary cross-entropy and mean squared error, with a weighting factor alpha to balance the two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fb4962d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5575313568115234\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom Loss combining Binary Cross-Entropy (BCE) and Mean Squared Error (MSE).\n",
    "\n",
    "    This loss function is useful when balancing between classification (BCE) \n",
    "    and regression (MSE) objectives. The `alpha` parameter controls the trade-off:\n",
    "      - `alpha = 1` focuses entirely on BCE.\n",
    "      - `alpha = 0` focuses entirely on MSE.\n",
    "\n",
    "    Usage:\n",
    "        loss_fn = CustomLoss(alpha=0.7)\n",
    "        loss = loss_fn(y_pred, y_true)\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=0.5):\n",
    "        \"\"\"\n",
    "        Initializes the CustomLoss class.\n",
    "\n",
    "        Args:\n",
    "            alpha (float): Weight for the BCE loss term (0 ≤ alpha ≤ 1).\n",
    "        \"\"\"\n",
    "        super(CustomLoss, self).__init__()  # Initialize the parent class (nn.Module).\n",
    "        self.alpha = alpha  # Store the alpha value for balancing the losses.\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Computes the weighted combination of BCE and MSE losses.\n",
    "\n",
    "        Args:\n",
    "            y_pred (torch.Tensor): Predicted values.\n",
    "            y_true (torch.Tensor): Ground truth values.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The combined loss value.\n",
    "        \"\"\"\n",
    "        # Compute Binary Cross-Entropy loss\n",
    "        bce_loss = F.binary_cross_entropy(y_pred, y_true)\n",
    "        \n",
    "        # Compute Mean Squared Error loss\n",
    "        mse_loss = F.mse_loss(y_pred, y_true)\n",
    "        \n",
    "        # Combine the losses using alpha for weighting\n",
    "        return self.alpha * bce_loss + (1 - self.alpha) * mse_loss\n",
    "\n",
    "    \n",
    "# Example usage\n",
    "y_pred = torch.sigmoid(torch.randn(5, 1, requires_grad=True))\n",
    "y_true = torch.randint(0, 2, (5, 1)).float()\n",
    "\n",
    "criterion = CustomLoss(alpha=0.7)\n",
    "loss = criterion(y_pred, y_true)\n",
    "print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850df60",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a>\n",
    "## <font color='blue'> 5. Example 3 </font>\n",
    "\n",
    "In this example the goal is to demonstrate the integration of a custom loss function in a training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "005e6534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 11.3141\n",
      "Epoch [20/100], Loss: 8.0045\n",
      "Epoch [30/100], Loss: 4.4206\n",
      "Epoch [40/100], Loss: 2.0854\n",
      "Epoch [50/100], Loss: 1.0460\n",
      "Epoch [60/100], Loss: 0.5868\n",
      "Epoch [70/100], Loss: 0.3805\n",
      "Epoch [80/100], Loss: 0.2915\n",
      "Epoch [90/100], Loss: 0.2548\n",
      "Epoch [100/100], Loss: 0.2403\n"
     ]
    }
   ],
   "source": [
    "# Define a simple custom MSE loss function\n",
    "class CustomMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return torch.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "# Define a simple neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 10)  # One input feature, 10 output features\n",
    "        self.fc2 = nn.Linear(10, 1)  # Output a single value\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create a random dataset\n",
    "x_train = torch.randn(100, 1)  # 100 data points, 1 feature\n",
    "y_train = 3 * x_train + 2 + torch.randn_like(x_train) * 0.5  # Linear relation with some noise\n",
    "\n",
    "# Initialize the model, optimizer, and loss function\n",
    "model = SimpleNN()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = CustomMSELoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x_train)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # Zero the gradients, backward pass, optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a911f",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- Custom Loss Function: CustomMSELoss is defined to compute the Mean Squared Error (MSE) between predicted values (y_pred) and actual values (y_true).\n",
    "\n",
    "\n",
    "- Model: A simple feedforward neural network (SimpleNN) with one hidden layer and ReLU activation.\n",
    "\n",
    "\n",
    "- Training Loop:\n",
    "\n",
    "    - The model makes predictions (y_pred).\n",
    "\n",
    "    - The loss is calculated using the custom loss function (loss_fn).\n",
    "\n",
    "    - Gradients are computed with loss.backward(), and the model parameters are updated with optimizer.step().\n",
    "\n",
    "This example demonstrates how to incorporate a custom loss function in a basic PyTorch training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85355031",
   "metadata": {},
   "source": [
    "<a name=\"references\"></a>\n",
    "## <font color='blue'> References </font>\n",
    "\n",
    "[PyTorch Documentation](https://pytorch.org/docs/stable/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
