{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78eb9d81-9915-471d-a23f-b05616ba8740",
   "metadata": {},
   "source": [
    "# <div style=\"text-align: center; color: #1a5276;\">Advanced Training</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d5100e-592d-4442-ba93-cfa6ddffced0",
   "metadata": {},
   "source": [
    "## <font color='blue'>  Table of Contents </font>\n",
    "\n",
    "1. [Introduction](#1)\n",
    "2. [Setup](#2)\n",
    "3. [Helper Functions](#3) \n",
    "4. [Data](#4) \n",
    "5. [Model](#5)\n",
    "6. [Training](#6) <br>\n",
    "    6.1. [Basic Training](#6.1) <br>\n",
    "    6.2. [Including a progress bar](#6.2) <br>\n",
    "    6.3. [Including a validation set and a custom metric](#6.3) <br>\n",
    "    6.4. [Code improvement](#6.4) <br>\n",
    "8. [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2536f186-9d07-43d4-a5dd-7f639905a182",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## <font color='blue'> 1. Introduction </font>\n",
    "\n",
    "https://gemini.google.com/app/c49f12a5fb1aef13?hl=es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d56b52e-689f-4793-9069-f37776d76270",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## <font color='blue'> 2. Setup </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c47489ce-2423-4eba-a9f9-92725bdbbee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9588c4d2-3390-4b27-80bc-1edc750b4168",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## <font color='blue'> 3. Data </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93c54dda-01ef-4338-88d0-55f4d0d677e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary data\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Synthetic binary data\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=0)\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Split: 70% train, 15% val, 15% test\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=0.5, random_state=0)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=32)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9f4fa9-26e8-4ad3-9dd9-40ced1e71efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d10094-4072-4b8c-bd58-7107991d2cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7cee58d-bf47-4f2c-91da-d23d42c6ff6a",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "1.1. Simple trainign\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "929c92c3-476c-4a61-87a1-6a48832296a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=20, out_features=32, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model (binary)\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(20, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 2)\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2972cc9-8877-43c2-b2a0-328c2d46f48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, metric_fn=None):\n",
    "    model.train()\n",
    "    running_loss, running_metric, total_samples = 0.0, 0.0, 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = labels.size(0)\n",
    "        running_loss += loss.item() * batch_size\n",
    "        if metric_fn:\n",
    "            running_metric += metric_fn(outputs, labels).item() * batch_size\n",
    "        total_samples += batch_size\n",
    "\n",
    "    return running_loss / total_samples, running_metric / total_samples if metric_fn else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78c6d9b4-ac5e-477c-8635-b8bd8a27c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device, metric_fn=None):\n",
    "    model.eval()\n",
    "    running_loss, running_metric, total_samples = 0.0, 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            batch_size = labels.size(0)\n",
    "            running_loss += loss.item() * batch_size\n",
    "            if metric_fn:\n",
    "                running_metric += metric_fn(outputs, labels).item() * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "    return running_loss / total_samples, running_metric / total_samples if metric_fn else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dffd3ac5-75da-4fca-9ee2-36ed99da5b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, train_loader, val_loader, test_loader,\n",
    "    criterion, optimizer, device,\n",
    "    metric_fn=None, epochs=10,\n",
    "    scheduler=None, early_stopping_patience=None\n",
    "):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    wait = 0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_metric': [], 'val_metric': []}\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss, train_metric = train_one_epoch(model, train_loader, criterion, optimizer, device, metric_fn)\n",
    "        val_loss, val_metric = evaluate(model, val_loader, criterion, device, metric_fn)\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_metric'].append(train_metric)\n",
    "        history['val_metric'].append(val_metric)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f}, Metric: {train_metric:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Metric: {val_metric:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if early_stopping_patience and wait >= early_stopping_patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"Loaded best model.\")\n",
    "\n",
    "    # Final test set evaluation (only once)\n",
    "    test_loss, test_metric = evaluate(model, test_loader, criterion, device, metric_fn)\n",
    "    print(f\"\\nFinal Test Loss: {test_loss:.4f}, Test Metric: {test_metric:.4f}\")\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f06ca31-be1a-480d-bbd7-27d2b0ce0ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 0.4410, Metric: 0.8314 | Val Loss: 0.2145, Metric: 0.9333\n",
      "Epoch 02 | Train Loss: 0.1712, Metric: 0.9329 | Val Loss: 0.1727, Metric: 0.9400\n",
      "Epoch 03 | Train Loss: 0.1241, Metric: 0.9586 | Val Loss: 0.1787, Metric: 0.9400\n",
      "Epoch 04 | Train Loss: 0.1004, Metric: 0.9686 | Val Loss: 0.1749, Metric: 0.9400\n",
      "Epoch 05 | Train Loss: 0.0870, Metric: 0.9729 | Val Loss: 0.1803, Metric: 0.9400\n",
      "Epoch 06 | Train Loss: 0.0720, Metric: 0.9829 | Val Loss: 0.1810, Metric: 0.9400\n",
      "Early stopping triggered.\n",
      "Loaded best model.\n",
      "\n",
      "Final Test Loss: 0.1209, Test Metric: 0.9800\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2)\n",
    "\n",
    "def accuracy_fn(outputs, labels):\n",
    "    preds = torch.argmax(outputs, dim=1)\n",
    "    return (preds == labels).float().mean()\n",
    "\n",
    "# Train with test set evaluation\n",
    "model, history = train_model(\n",
    "    model, train_loader, val_loader, test_loader,\n",
    "    criterion, optimizer, device,\n",
    "    metric_fn=accuracy_fn,\n",
    "    epochs=20,\n",
    "    scheduler=scheduler,\n",
    "    early_stopping_patience=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b9fc13-e76c-489a-9445-cd4226be4a57",
   "metadata": {},
   "source": [
    "### Multiple metrics\n",
    "\n",
    "\n",
    "\n",
    "### using torchmetrics to compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c45113c-ba9c-4f28-9f4b-42bd9c55c9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68fc0ec-0df2-4cf7-ae96-d8bc3360b311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cee84d0-76d5-47ab-8529-f59be46cc02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a6a68-c30d-4c74-99a7-c813382d6b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
